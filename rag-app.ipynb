{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bca22bfc-a776-4354-beca-9585b1b4e641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Import Libraries\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "628043d2-e1d4-4f44-9747-c8b8b3578e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY']=os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "201e3c40-5956-4fc1-956c-4f5aa9a4676e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 21 0 (offset 0)\n",
      "Ignoring wrong pointing object 62 0 (offset 0)\n",
      "Ignoring wrong pointing object 74 0 (offset 0)\n",
      "Ignoring wrong pointing object 139 0 (offset 0)\n",
      "Ignoring wrong pointing object 151 0 (offset 0)\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "documents=SimpleDirectoryReader(\"data\").load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89bf4863-1285-4d7f-9f8c-72927c70a2c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d7ab238eaf2487cb7d60998bdcab2bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84be40e99ab84e3e898512fc8d35c959",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying llama_index.embeddings.openai.base.get_embeddings in 0.17893254810974812 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}.\n"
     ]
    }
   ],
   "source": [
    "# Create the index with a progress display\n",
    "index = VectorStoreIndex.from_documents(documents, show_progress=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0ba84e1a-5050-4ee2-ad61-8883bd4d42e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine=index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6c6aea3d-1f11-46c7-8308-b5fe1692115f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.postprocessor import SimilarityPostprocessor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc54f23-bf8f-4494-82b3-42b9b005b68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever=VectorIndexRetriever(index=index, similarity_top_k=4)\n",
    "postprocessor=SimilarityPostprocessor(similarity_cutoff=0.80)\n",
    "query_engine=RetrieverQueryEngine(retriever=retriever,node_postprocessors=[postprocessor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2ed15e-8f47-4bec-a5d1-71c70797fc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(\"What are Transformers?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a4bc66-2b79-45ac-8934-63d5139d0d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.response.pprint_utils import pprint_response\n",
    "pprint_response(response,show_source=True)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4f5316b4-2e9e-42fb-9a0f-e6fd1e5f94b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 21 0 (offset 0)\n",
      "Ignoring wrong pointing object 62 0 (offset 0)\n",
      "Ignoring wrong pointing object 74 0 (offset 0)\n",
      "Ignoring wrong pointing object 139 0 (offset 0)\n",
      "Ignoring wrong pointing object 151 0 (offset 0)\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    SimpleDirectoryReader,\n",
    "    StorageContext,\n",
    "    load_index_from_storage,\n",
    ")\n",
    "\n",
    "# check if storage already exists\n",
    "PERSIST_DIR = \"./storage\"\n",
    "if not os.path.exists(PERSIST_DIR):\n",
    "    # load the documents and create the index\n",
    "    documents = SimpleDirectoryReader(\"data\").load_data()\n",
    "    index = VectorStoreIndex.from_documents(documents)\n",
    "    # store it for later\n",
    "    index.storage_context.persist(persist_dir=PERSIST_DIR)\n",
    "else:\n",
    "    # load the existing index\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=PERSIST_DIR)\n",
    "    index = load_index_from_storage(storage_context)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1c4269a9-37a5-430e-ae1c-0197db7e50e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers are a model architecture that relies entirely on an attention mechanism to establish global dependencies between input and output, eliminating the need for recurrence in sequence transduction tasks. This approach allows for increased parallelization during training and has shown significant improvements in translation quality with relatively short training times.\n"
     ]
    }
   ],
   "source": [
    "# either way we can now query the index\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What are transformers?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eca79e1-60a2-4bcf-8fd3-690f803f2d63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
